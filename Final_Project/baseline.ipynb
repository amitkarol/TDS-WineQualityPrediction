{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Notebook cell #1: Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, r2_score, mean_absolute_error,\n",
    "    accuracy_score, f1_score, classification_report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline Regression (Amsterdam) ===\n",
      "R²   : 0.5513\n",
      "RMSE : 209.1149\n",
      "MAE  : 153.7245\n",
      "---------------------------------------\n",
      "\n",
      "Data saved as 'amsterdam_weekdays_clean.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amit\\AppData\\Local\\Temp\\ipykernel_1964\\3937708130.py:14: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({False: 0, True: 1, 'FALSE': 0, 'TRUE': 1})\n",
      "C:\\Users\\Amit\\AppData\\Local\\Temp\\ipykernel_1964\\3937708130.py:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({False: 0, True: 1, 'FALSE': 0, 'TRUE': 1})\n",
      "C:\\Users\\Amit\\AppData\\Local\\Temp\\ipykernel_1964\\3937708130.py:28: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({False: 0, True: 1, 'FALSE': 0, 'TRUE': 1})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Load your dataset (adjust path as needed)\n",
    "df_amsterdam = pd.read_csv(\"Data/amsterdam_weekdays.csv\")\n",
    "\n",
    "# Convert booleans/strings to 0/1 for host_is_superhost, room_private, room_shared\n",
    "if 'host_is_superhost' in df_amsterdam.columns:\n",
    "    df_amsterdam['host_is_superhost'] = (\n",
    "        df_amsterdam['host_is_superhost']\n",
    "        .replace({False: 0, True: 1, 'FALSE': 0, 'TRUE': 1})\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "if 'room_private' in df_amsterdam.columns:\n",
    "    df_amsterdam['room_private'] = (\n",
    "        df_amsterdam['room_private']\n",
    "        .replace({False: 0, True: 1, 'FALSE': 0, 'TRUE': 1})\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "if 'room_shared' in df_amsterdam.columns:\n",
    "    df_amsterdam['room_shared'] = (\n",
    "        df_amsterdam['room_shared']\n",
    "        .replace({False: 0, True: 1, 'FALSE': 0, 'TRUE': 1})\n",
    "        .astype(int)\n",
    "    )\n",
    "\n",
    "# One-Hot encode 'room_type' if it exists \n",
    "#    (handles 'Private room', 'Entire home/apt', 'Shared room', etc.)\n",
    "if 'room_type' in df_amsterdam.columns:\n",
    "    df_amsterdam = pd.get_dummies(df_amsterdam, columns=['room_type'], prefix='room_type')\n",
    "\n",
    "# Force any remaining boolean columns to int (if any were created by get_dummies)\n",
    "bool_cols = df_amsterdam.select_dtypes(include='bool').columns\n",
    "for col in bool_cols:\n",
    "    df_amsterdam[col] = df_amsterdam[col].astype(int)\n",
    "\n",
    "# Define target column\n",
    "target_col = \"realSum\"\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X_amsterdam = df_amsterdam.drop(columns=[target_col])\n",
    "y_amsterdam = df_amsterdam[target_col]\n",
    "\n",
    "# Train/Test split\n",
    "X_train_amst, X_test_amst, y_train_amst, y_test_amst = train_test_split(\n",
    "    X_amsterdam, y_amsterdam, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Baseline Linear Regression Model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_amst, y_train_amst)\n",
    "\n",
    "# Predictions & Metrics\n",
    "y_pred_amst = lin_reg.predict(X_test_amst)\n",
    "\n",
    "r2 = r2_score(y_test_amst, y_pred_amst)\n",
    "mse = mean_squared_error(y_test_amst, y_pred_amst)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_amst, y_pred_amst)\n",
    "\n",
    "print(\"=== Baseline Regression (Amsterdam) ===\")\n",
    "print(f\"R²   : {r2:.4f}\")\n",
    "print(f\"RMSE : {rmse:.4f}\")\n",
    "print(f\"MAE  : {mae:.4f}\")\n",
    "print(\"---------------------------------------\\n\")\n",
    "\n",
    "# Save cleaned data to CSV\n",
    "df_amsterdam.to_csv(\"Data/amsterdam_weekdays_clean.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amit\\AppData\\Local\\Temp\\ipykernel_1964\\758508982.py:25: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({'true': 1, 'false': 0, 'yes': 1, 'no': 0})\n",
      "C:\\Users\\Amit\\AppData\\Local\\Temp\\ipykernel_1964\\758508982.py:25: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({'true': 1, 'false': 0, 'yes': 1, 'no': 0})\n",
      "C:\\Users\\Amit\\AppData\\Local\\Temp\\ipykernel_1964\\758508982.py:25: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({'true': 1, 'false': 0, 'yes': 1, 'no': 0})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows after forcing booleans to 0/1:\n",
      "\n",
      "   Hours_Studied  Attendance  Extracurricular_Activities  Sleep_Hours  Previous_Scores  Internet_Access  Tutoring_Sessions  Physical_Activity  Learning_Disabilities  Exam_Score  Passed  Parental_Involvement_Low  Parental_Involvement_Medium  Access_to_Resources_Low  Access_to_Resources_Medium  Motivation_Level_Low  Motivation_Level_Medium  Family_Income_Low  Family_Income_Medium  Teacher_Quality_Low  Teacher_Quality_Medium  School_Type_Public  Peer_Influence_Neutral  Peer_Influence_Positive  Parental_Education_Level_High School  Parental_Education_Level_Postgraduate  Distance_from_Home_Moderate  Distance_from_Home_Near  Gender_Male\n",
      "0             23          84                           0            7               73                1                  0                  3                      0          67       1                         1                            0                        0                           0                     1                        0                  1                     0                    0                       1                   1                       0                        1                                     1                                      0                            0                        1            1\n",
      "1             19          64                           0            8               59                1                  2                  4                      0          61       1                         1                            0                        0                           1                     1                        0                  0                     1                    0                       1                   1                       0                        0                                     0                                      0                            1                        0            0\n",
      "2             24          98                           1            7               91                1                  2                  4                      0          74       1                         0                            1                        0                           1                     0                        1                  0                     1                    0                       1                   1                       1                        0                                     0                                      1                            0                        1            1\n",
      "3             29          89                           1            8               98                1                  1                  4                      0          71       1                         1                            0                        0                           1                     0                        1                  0                     1                    0                       1                   1                       0                        0                                     1                                      0                            1                        0            1\n",
      "4             19          92                           1            6               65                1                  3                  4                      0          70       1                         0                            1                        0                           1                     0                        1                  0                     1                    0                       0                   1                       1                        0                                     0                                      0                            0                        1            0\n",
      "5             19          88                           1            8               89                1                  3                  3                      0          71       1                         0                            1                        0                           1                     0                        1                  0                     1                    0                       1                   1                       0                        1                                     0                                      1                            0                        1            1\n",
      "6             29          84                           1            7               68                1                  1                  2                      0          67       1                         0                            1                        1                           0                     1                        0                  1                     0                    0                       1                   0                       1                        0                                     1                                      0                            1                        0            1\n",
      "7             25          78                           1            6               50                1                  1                  2                      0          66       1                         1                            0                        0                           0                     0                        1                  0                     0                    0                       0                   1                       0                        0                                     1                                      0                            0                        0            1\n",
      "8             17          94                           0            6               80                1                  0                  1                      0          69       1                         0                            1                        0                           0                     0                        0                  0                     1                    1                       0                   0                       1                        0                                     0                                      0                            0                        1            1\n",
      "9             23          98                           1            8               71                1                  0                  5                      0          72       1                         0                            1                        0                           1                     0                        1                  0                     0                    0                       0                   1                       0                        1                                     1                                      0                            1                        0            1\n",
      "\n",
      "=== Baseline Classification (Student Performance) ===\n",
      "Accuracy  : 0.9970\n",
      "Precision : 0.9977\n",
      "Recall    : 0.9992\n",
      "F1 Score  : 0.9985\n",
      "---------------------------------------\n",
      "\n",
      "Preprocessing complete. Cleaned dataset saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "student_data = pd.read_csv(\"Data/StudentPerformanceFactors.csv\")\n",
    "\n",
    "# Create a 'Passed' column from 'Exam_Score' (1 = Pass if >= 60, else 0)\n",
    "student_data['Passed'] = (student_data['Exam_Score'] >= 60).astype(int)\n",
    "\n",
    "# Convert boolean/string columns to 0/1\n",
    "boolean_columns = ['Internet_Access', 'Learning_Disabilities', 'Extracurricular_Activities']\n",
    "for col in boolean_columns:\n",
    "    if col in student_data.columns:\n",
    "        # If column is already boolean dtype\n",
    "        if student_data[col].dtype == bool:\n",
    "            student_data[col] = student_data[col].astype(int)  # True -> 1, False -> 0\n",
    "        else:\n",
    "            # Convert strings like \"True\"/\"False\"/\"Yes\"/\"No\" to 1/0\n",
    "            student_data[col] = (\n",
    "                student_data[col]\n",
    "                .astype(str)\n",
    "                .str.lower()\n",
    "                .replace({'true': 1, 'false': 0, 'yes': 1, 'no': 0})\n",
    "                .fillna(0)\n",
    "                .astype(int)\n",
    "            )\n",
    "\n",
    "# Identify other categorical columns for One-Hot Encoding\n",
    "categorical_cols = [\n",
    "    'Parental_Involvement', 'Access_to_Resources', 'Motivation_Level', 'Family_Income',\n",
    "    'Teacher_Quality', 'School_Type', 'Peer_Influence', 'Parental_Education_Level',\n",
    "    'Distance_from_Home', 'Gender'\n",
    "]\n",
    "\n",
    "# Apply One-Hot Encoding to these columns\n",
    "student_data = pd.get_dummies(student_data, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Force any remaining boolean columns to int (e.g., from get_dummies)\n",
    "bool_cols = student_data.select_dtypes(include=\"bool\").columns\n",
    "for col in bool_cols:\n",
    "    student_data[col] = student_data[col].astype(int)\n",
    "\n",
    "# Show first 10 rows to verify all are now 0/1 or numeric\n",
    "print(\"\\nFirst 10 rows after forcing booleans to 0/1:\\n\")\n",
    "print(student_data.head(10).to_string())\n",
    "\n",
    "# Define target column\n",
    "target_col = \"Passed\"\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X_student = student_data.drop(columns=[\"Exam_Score\", target_col])\n",
    "y_student = student_data[target_col]\n",
    "\n",
    "# Train/Test split\n",
    "X_train_student, X_test_student, y_train_student, y_test_student = train_test_split(\n",
    "    X_student, y_student, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train a baseline Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train_student, y_train_student)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_student = log_reg.predict(X_test_student)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_test_student, y_pred_student)\n",
    "precision = precision_score(y_test_student, y_pred_student)\n",
    "recall = recall_score(y_test_student, y_pred_student)\n",
    "f1 = f1_score(y_test_student, y_pred_student)\n",
    "\n",
    "print(\"\\n=== Baseline Classification (Student Performance) ===\")\n",
    "print(f\"Accuracy  : {accuracy:.4f}\")\n",
    "print(f\"Precision : {precision:.4f}\")\n",
    "print(f\"Recall    : {recall:.4f}\")\n",
    "print(f\"F1 Score  : {f1:.4f}\")\n",
    "print(\"---------------------------------------\\n\")\n",
    "\n",
    "# Save the processed dataset\n",
    "student_data.to_csv(\"Data/StudentPerformanceFactors_clean.csv\", index=False)\n",
    "print(\"Preprocessing complete. Cleaned dataset saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

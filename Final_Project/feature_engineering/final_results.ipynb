{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabular Data Science â€“ Final Research Project\n",
    "### Overview\n",
    "This notebook presents an automated feature engineering approach to improve model performance across multiple datasets. We compare a baseline model trained on the original features with an enhanced model that includes automatically generated features.\n",
    "### Approach\n",
    "1. Baseline Model: Train and evaluate a simple model on the raw dataset.\n",
    "2. Feature Engineering: Automatically generate, filter, and rank new features.\n",
    "3. Enhanced Model: Train and evaluate a model with the engineered features.\n",
    "4. Comparison: Compare baseline vs. enhanced model performance using statistical tests.\n",
    "### Datasets Used\n",
    "We evaluate our approach on four different datasets:\n",
    "- Cancer Patient Data (Classification)\n",
    "- Amsterdam Rental Prices (Regression)\n",
    "- Student Performance Factors (Classification)\n",
    "- Weather Data (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,r2_score, mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import ttest_rel\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from scipy.stats import wilcoxon\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Ensure the feature_engineering module is in the Python path\n",
    "sys.path.append(os.path.abspath(\"feature_engineering\"))\n",
    "from feature_generator import SemiAutomatedFeatureEngineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 1: Cancer Patient Data (Classification)\n",
    "Goal: Predict cancer severity level based on patient attributes.\n",
    "\n",
    "- Type: Classification (Target: Level)\n",
    "- Baseline Model: RandomForestClassifier\n",
    "- Enhanced Model: Random Forest with Engineered Features\n",
    "- Comparison Metrics: Accuracy, Precision, Recall, F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Model Performance:\n",
      "{'Accuracy': 0.9354838709677419, 'Precision': 0.946236559139785, 'Recall': 0.9354838709677419, 'F1 Score': 0.9319648093841643}\n",
      "\n",
      "Running Feature Engineering...\n",
      "Generating new features...\n",
      "Filtering irrelevant features...\n",
      "Computing feature importance...\n",
      "\n",
      "Important Features:\n",
      " Air Pollution_times_Coughing of Blood          0.014227\n",
      "Air Pollution_plus_Coughing of Blood           0.012577\n",
      "Alcohol use_plus_Fatigue                       0.011524\n",
      "Balanced Diet_div_Clubbing of Finger Nails     0.010567\n",
      "Balanced Diet_plus_Coughing of Blood           0.010485\n",
      "                                                 ...   \n",
      "Dust Allergy_times_Dry Cough                   0.000000\n",
      "Dust Allergy_times_Frequent Cold               0.000000\n",
      "Dust Allergy_minus_Clubbing of Finger Nails    0.000000\n",
      "Dust Allergy_minus_Wheezing                    0.000000\n",
      "Dry Cough_div_Snoring                          0.000000\n",
      "Length: 921, dtype: float64\n",
      "Training and evaluating the model...\n",
      "\n",
      "Model Performance with Engineered Features: {'Accuracy': 0.9354838709677419, 'Precision': 0.946236559139785, 'Recall': 0.9354838709677419, 'F1 Score': 0.9319648093841643}\n",
      "\n",
      "Comparison Between Baseline and Enhanced Model:\n",
      "Baseline Model: {'Accuracy': 0.9354838709677419, 'Precision': 0.946236559139785, 'Recall': 0.9354838709677419, 'F1 Score': 0.9319648093841643}\n",
      "Enhanced Model: {'Accuracy': 0.967741935483871, 'Precision': 0.969758064516129, 'Recall': 0.967741935483871, 'F1 Score': 0.9667959511872103}\n",
      "\n",
      "Paired T-Test: t=-12.4158, p=0.0011\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# 1. Load & Preprocess the Data\n",
    "###############################################################################\n",
    "dataset_path = os.path.abspath(\"../Data/cancer_patient.csv\")\n",
    "df_cancer = pd.read_csv(dataset_path)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "if 'index' in df_cancer.columns:\n",
    "    df_cancer.drop(columns=['index'], inplace=True)\n",
    "if 'Patient Id' in df_cancer.columns:\n",
    "    df_cancer.drop(columns=['Patient Id'], inplace=True)\n",
    "\n",
    "df_cancer.drop_duplicates(inplace=True)\n",
    "\n",
    "# Encode the target column\n",
    "label_encoder = LabelEncoder()\n",
    "df_cancer['Level'] = label_encoder.fit_transform(df_cancer['Level'])\n",
    "\n",
    "# Save the cleaned dataset\n",
    "cleaned_path = os.path.abspath(\"../Data/cancer_patient_clean.csv\")\n",
    "df_cancer.to_csv(cleaned_path, index=False)\n",
    "\n",
    "###############################################################################\n",
    "# 2. Baseline Model Training\n",
    "###############################################################################\n",
    "X = df_cancer.drop(columns=['Level'])\n",
    "y = df_cancer['Level']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Simple baseline model\n",
    "baseline_model = RandomForestClassifier(\n",
    "    n_estimators=50, max_depth=5, min_samples_split=10, random_state=42\n",
    ")\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate baseline model\n",
    "y_pred_baseline = baseline_model.predict(X_test)\n",
    "baseline_results = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_baseline),\n",
    "    \"Precision\": precision_score(y_test, y_pred_baseline, average='weighted'),\n",
    "    \"Recall\": recall_score(y_test, y_pred_baseline, average='weighted'),\n",
    "    \"F1 Score\": f1_score(y_test, y_pred_baseline, average='weighted')\n",
    "}\n",
    "\n",
    "print(\"\\nBaseline Model Performance:\")\n",
    "print(baseline_results)\n",
    "\n",
    "###############################################################################\n",
    "# 3. Feature Engineering (SemiAutomatedFeatureEngineering)\n",
    "###############################################################################\n",
    "print(\"\\nRunning Feature Engineering...\")\n",
    "feature_engineer = SemiAutomatedFeatureEngineering(\n",
    "    df_cancer.copy(), \n",
    "    target_column=\"Level\",\n",
    "    task=\"classification\"\n",
    ")\n",
    "enhanced_results = feature_engineer.run_pipeline()\n",
    "\n",
    "###############################################################################\n",
    "# 4. Train a New Model on the Enhanced Data\n",
    "###############################################################################\n",
    "# The feature_engineer.df now has new features\n",
    "df_enhanced = feature_engineer.df\n",
    "X_enhanced = df_enhanced.drop(columns=[\"Level\"])\n",
    "y_enhanced = df_enhanced[\"Level\"]\n",
    "\n",
    "X_train_enhanced, X_test_enhanced, y_train_enhanced, y_test_enhanced = train_test_split(\n",
    "    X_enhanced, y_enhanced, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "enhanced_model = RandomForestClassifier(\n",
    "    n_estimators=50, max_depth=5, min_samples_split=10, random_state=42\n",
    ")\n",
    "enhanced_model.fit(X_train_enhanced, y_train_enhanced)\n",
    "\n",
    "# Evaluate the enhanced model\n",
    "y_pred_enhanced = enhanced_model.predict(X_test_enhanced)\n",
    "enhanced_model_results = {\n",
    "    \"Accuracy\": accuracy_score(y_test_enhanced, y_pred_enhanced),\n",
    "    \"Precision\": precision_score(y_test_enhanced, y_pred_enhanced, average='weighted'),\n",
    "    \"Recall\": recall_score(y_test_enhanced, y_pred_enhanced, average='weighted'),\n",
    "    \"F1 Score\": f1_score(y_test_enhanced, y_pred_enhanced, average='weighted')\n",
    "}\n",
    "\n",
    "###############################################################################\n",
    "# 5. Compare Baseline vs. Enhanced\n",
    "###############################################################################\n",
    "print(\"\\nComparison Between Baseline and Enhanced Model:\")\n",
    "print(\"Baseline Model:\", baseline_results)\n",
    "print(\"Enhanced Model:\", enhanced_model_results)\n",
    "\n",
    "# Statistical Test\n",
    "baseline_scores = np.array(list(baseline_results.values()))\n",
    "enhanced_scores = np.array(list(enhanced_model_results.values()))\n",
    "t_stat, p_value = ttest_rel(baseline_scores, enhanced_scores)\n",
    "print(f\"\\nPaired T-Test: t={t_stat:.4f}, p={p_value:.4f}\")\n",
    "\n",
    "###############################################################################\n",
    "# 6. SHAP Analysis for Both Models\n",
    "###############################################################################\n",
    "# print(\"\\nRunning SHAP Analysis for Baseline Model...\")\n",
    "# explainer_baseline = shap.Explainer(baseline_model, X_test)\n",
    "# shap_values_baseline = explainer_baseline(X_test)\n",
    "\n",
    "# if len(shap_values_baseline.values.shape) == 3:\n",
    "#     # Multi-class scenario\n",
    "#     for class_idx in range(shap_values_baseline.values.shape[2]):\n",
    "#         plt.figure(figsize=(15, 10))\n",
    "#         shap.summary_plot(shap_values_baseline[..., class_idx], X_test, \n",
    "#                           feature_names=X_test.columns, show=True)\n",
    "#         plt.savefig(f\"shap_baseline_model_class_{class_idx}.png\", \n",
    "#                     dpi=300, bbox_inches=\"tight\")\n",
    "#         plt.close()\n",
    "#         print(f\"SHAP plot (Baseline, Class {class_idx}) saved.\")\n",
    "\n",
    "# print(\"\\nRunning SHAP Analysis for Enhanced Model...\")\n",
    "# explainer_enhanced = shap.Explainer(enhanced_model, X_test_enhanced)\n",
    "# shap_values_enhanced = explainer_enhanced(X_test_enhanced)\n",
    "\n",
    "# if len(shap_values_enhanced.values.shape) == 3:\n",
    "#     # Multi-class scenario\n",
    "#     for class_idx in range(shap_values_enhanced.values.shape[2]):\n",
    "#         plt.figure(figsize=(15, 10))\n",
    "#         shap.summary_plot(shap_values_enhanced[..., class_idx], X_test_enhanced, \n",
    "#                           feature_names=X_test_enhanced.columns, show=True)\n",
    "#         plt.savefig(f\"shap_enhanced_model_class_{class_idx}.png\", \n",
    "#                     dpi=300, bbox_inches=\"tight\")\n",
    "#         plt.close()\n",
    "#         print(f\"SHAP plot (Enhanced, Class {class_idx}) saved.\")\n",
    "\n",
    "# print(\"SHAP analysis complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2: Amsterdam Rental Prices (Regression)\n",
    "Goal: Predict rental prices of properties in Amsterdam.\n",
    "\n",
    "- Type: Regression (Target: realSum)\n",
    "- Baseline Model: RandomForestRegressor\n",
    "- Enhanced Model: Random Forest with Engineered Features\n",
    "- Comparison Metrics: RÂ², RMSE, MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amit\\AppData\\Local\\Temp\\ipykernel_16580\\4207977420.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_amsterdam[col] = df_amsterdam[col].replace({\n",
      "C:\\Users\\Amit\\AppData\\Local\\Temp\\ipykernel_16580\\4207977420.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_amsterdam[col] = df_amsterdam[col].replace({\n",
      "C:\\Users\\Amit\\AppData\\Local\\Temp\\ipykernel_16580\\4207977420.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_amsterdam[col] = df_amsterdam[col].replace({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Amsterdam Baseline Model ===\n",
      "{'RÂ²': 0.481964703404132, 'RMSE': 224.68364147185966, 'MAE': 148.43478257371325}\n",
      "\n",
      "Running Semi-Automated Feature Engineering (Amsterdam)...\n",
      "Generating new features...\n",
      "Filtering irrelevant features...\n",
      "Computing feature importance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|===================| 1085/1103 [00:47<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Important Features:\n",
      " person_capacity_plus_room_type_Entire home/apt     17.286412\n",
      "room_private_div_person_capacity                    9.517621\n",
      "person_capacity_minus_metro_dist                    9.327779\n",
      "bedrooms_plus_room_type_Entire home/apt             8.414398\n",
      "person_capacity_times_room_type_Entire home/apt     7.440377\n",
      "                                                     ...    \n",
      "room_shared_plus_room_type_Entire home/apt          0.001522\n",
      "room_private                                        0.001091\n",
      "room_private_plus_room_type_Private room            0.000826\n",
      "room_private_times_room_type_Private room           0.000628\n",
      "room_private_minus_room_type_Entire home/apt        0.000443\n",
      "Length: 545, dtype: float64\n",
      "Training and evaluating the model...\n",
      "\n",
      "Model Performance with Engineered Features: {'RÂ²': 0.570615190219463, 'RMSE': 204.55736294415533}\n",
      "\n",
      "=== Amsterdam Enhanced Model ===\n",
      "{'RÂ²': 0.5824470572475611, 'RMSE': 201.71934648304074, 'MAE': 134.1443843798962}\n",
      "\n",
      "Comparison Baseline vs. Enhanced (Amsterdam)\n",
      "Baseline: {'RÂ²': 0.481964703404132, 'RMSE': 224.68364147185966, 'MAE': 148.43478257371325}\n",
      "Enhanced: {'RÂ²': 0.5824470572475611, 'RMSE': 201.71934648304074, 'MAE': 134.1443843798962}\n",
      "Wilcoxon: statistic=1.0000, pvalue=0.5000\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# 1. LOAD & CLEAN (Baseline)\n",
    "###############################################################################\n",
    "dataset_path = os.path.abspath(\"../Data/amsterdam_weekdays.csv\")\n",
    "df_amsterdam = pd.read_csv(dataset_path)\n",
    "\n",
    "# Convert booleans/strings to 0/1\n",
    "for col in [\"host_is_superhost\", \"room_private\", \"room_shared\"]:\n",
    "    if col in df_amsterdam.columns:\n",
    "        df_amsterdam[col] = df_amsterdam[col].replace({\n",
    "            False: 0, True: 1, \"FALSE\": 0, \"TRUE\": 1\n",
    "        }).astype(int)\n",
    "\n",
    "# One-hot encode 'room_type' if present\n",
    "if \"room_type\" in df_amsterdam.columns:\n",
    "    df_amsterdam = pd.get_dummies(df_amsterdam, columns=[\"room_type\"], prefix=\"room_type\")\n",
    "\n",
    "# Convert any leftover bools\n",
    "bool_cols = df_amsterdam.select_dtypes(include='bool').columns\n",
    "df_amsterdam[bool_cols] = df_amsterdam[bool_cols].astype(int)\n",
    "\n",
    "target_col = \"realSum\"\n",
    "if target_col not in df_amsterdam.columns:\n",
    "    raise KeyError(f\"Target '{target_col}' not found in amsterdam_weekdays.csv\")\n",
    "\n",
    "# (Optional) Save cleaned\n",
    "cleaned_path = os.path.abspath(\"../Data/amsterdam_weekdays_clean.csv\")\n",
    "df_amsterdam.to_csv(cleaned_path, index=False)\n",
    "\n",
    "# Prepare baseline data\n",
    "X_amst = df_amsterdam.drop(columns=[target_col])\n",
    "y_amst = df_amsterdam[target_col]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_amst_scaled = pd.DataFrame(scaler.fit_transform(X_amst), columns=X_amst.columns)\n",
    "\n",
    "X_train_amst, X_test_amst, y_train_amst, y_test_amst = train_test_split(\n",
    "    X_amst_scaled, y_amst, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Baseline model\n",
    "baseline_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "baseline_model.fit(X_train_amst, y_train_amst)\n",
    "\n",
    "# Evaluate baseline\n",
    "y_pred_baseline = baseline_model.predict(X_test_amst)\n",
    "baseline_metrics = {\n",
    "    \"RÂ²\": r2_score(y_test_amst, y_pred_baseline),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_test_amst, y_pred_baseline)),\n",
    "    \"MAE\": mean_absolute_error(y_test_amst, y_pred_baseline),\n",
    "}\n",
    "print(\"\\n=== Amsterdam Baseline Model ===\")\n",
    "print(baseline_metrics)\n",
    "\n",
    "###############################################################################\n",
    "# 2. SEMI-AUTOMATED FEATURE ENGINEERING\n",
    "###############################################################################\n",
    "print(\"\\nRunning Semi-Automated Feature Engineering (Amsterdam)...\")\n",
    "\n",
    "feature_engineer = SemiAutomatedFeatureEngineering(\n",
    "    df_amsterdam.copy(),  # pass a copy\n",
    "    target_column=target_col,\n",
    "    task=\"regression\"\n",
    "    # correlation_threshold=0.05, variance_threshold=0.01 (if your class supports those)\n",
    ")\n",
    "pipeline_results = feature_engineer.run_pipeline()  # This prints out results, features, etc.\n",
    "\n",
    "# The pipeline's final DataFrame with new features\n",
    "df_amst_enh = feature_engineer.df\n",
    "X_enh = df_amst_enh.drop(columns=[target_col])\n",
    "y_enh = df_amst_enh[target_col]\n",
    "\n",
    "# Scale again with new features\n",
    "X_enh_scaled = pd.DataFrame(scaler.fit_transform(X_enh), columns=X_enh.columns)\n",
    "\n",
    "X_train_enh, X_test_enh, y_train_enh, y_test_enh = train_test_split(\n",
    "    X_enh_scaled, y_enh, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "enh_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "enh_model.fit(X_train_enh, y_train_enh)\n",
    "\n",
    "y_pred_enh = enh_model.predict(X_test_enh)\n",
    "enhanced_metrics = {\n",
    "    \"RÂ²\": r2_score(y_test_enh, y_pred_enh),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(y_test_enh, y_pred_enh)),\n",
    "    \"MAE\": mean_absolute_error(y_test_enh, y_pred_enh),\n",
    "}\n",
    "print(\"\\n=== Amsterdam Enhanced Model ===\")\n",
    "print(enhanced_metrics)\n",
    "\n",
    "# Compare\n",
    "print(\"\\nComparison Baseline vs. Enhanced (Amsterdam)\")\n",
    "print(\"Baseline:\", baseline_metrics)\n",
    "print(\"Enhanced:\", enhanced_metrics)\n",
    "\n",
    "base_scores = np.array(list(baseline_metrics.values()))\n",
    "enh_scores = np.array(list(enhanced_metrics.values()))\n",
    "stat, pval = wilcoxon(base_scores, enh_scores)\n",
    "print(f\"Wilcoxon: statistic={stat:.4f}, pvalue={pval:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 3: Student Performance (Classification)\n",
    "Goal: Predict whether a student passes based on academic and lifestyle factors.\n",
    "\n",
    "- Type: Classification (Target: Passed)\n",
    "- Baseline Model: RandomForestClassifier\n",
    "- Enhanced Model: Random Forest with Engineered Features\n",
    "- Comparison Metrics: Accuracy, Precision, Recall, F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amit\\AppData\\Local\\Temp\\ipykernel_16580\\1828645231.py:40: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\"true\": 1, \"false\": 0, \"yes\": 1, \"no\": 0})\n",
      "C:\\Users\\Amit\\AppData\\Local\\Temp\\ipykernel_16580\\1828645231.py:40: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\"true\": 1, \"false\": 0, \"yes\": 1, \"no\": 0})\n",
      "C:\\Users\\Amit\\AppData\\Local\\Temp\\ipykernel_16580\\1828645231.py:40: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({\"true\": 1, \"false\": 0, \"yes\": 1, \"no\": 0})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Students Baseline Model ===\n",
      "{'Accuracy': 0.9916792738275341, 'Precision': 0.9834277821391052, 'Recall': 0.9916792738275341, 'F1 Score': 0.9875362916732983}\n",
      "\n",
      "Running Semi-Automated Feature Engineering (Students)...\n",
      "Generating new features...\n",
      "Filtering irrelevant features...\n",
      "Computing feature importance...\n",
      "\n",
      "Important Features:\n",
      " Exam_Score                                               0.046962\n",
      "Learning_Disabilities_plus_Exam_Score                    0.041836\n",
      "Exam_Score_plus_Teacher_Quality_Low                      0.033608\n",
      "Exam_Score_plus_Parental_Education_Level_Postgraduate    0.032655\n",
      "Internet_Access_minus_Exam_Score                         0.022138\n",
      "                                                           ...   \n",
      "Internet_Access_minus_Access_to_Resources_Low            0.000000\n",
      "Internet_Access_minus_Motivation_Level_Low               0.000000\n",
      "Internet_Access_times_Distance_from_Home_Near            0.000000\n",
      "Tutoring_Sessions_minus_Learning_Disabilities            0.000000\n",
      "Hours_Studied                                            0.000000\n",
      "Length: 273, dtype: float64\n",
      "Training and evaluating the model...\n",
      "\n",
      "Model Performance with Engineered Features: {'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'F1 Score': 1.0}\n",
      "\n",
      "=== Students Enhanced Model ===\n",
      "{'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'F1 Score': 1.0}\n",
      "\n",
      "Compare Baseline vs. Enhanced (Students):\n",
      "Baseline: {'Accuracy': 0.9916792738275341, 'Precision': 0.9834277821391052, 'Recall': 0.9916792738275341, 'F1 Score': 0.9875362916732983}\n",
      "Enhanced: {'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'F1 Score': 1.0}\n",
      "\n",
      "Wilcoxon: statistic=0.0000, pvalue=0.1250\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# 1. BASELINE\n",
    "###############################################################################\n",
    "df_students = pd.read_csv(\"../Data/StudentPerformanceFactors.csv\")\n",
    "\n",
    "# Create \"Passed\" from \"Exam_Score\"\n",
    "if \"Exam_Score\" not in df_students.columns:\n",
    "    raise KeyError(\"No 'Exam_Score' column found; cannot create 'Passed' column.\")\n",
    "df_students[\"Passed\"] = (df_students[\"Exam_Score\"] >= 60).astype(int)\n",
    "\n",
    "# Convert boolean-like columns\n",
    "bool_cols_list = [\"Internet_Access\", \"Learning_Disabilities\", \"Extracurricular_Activities\"]\n",
    "for col in bool_cols_list:\n",
    "    if col in df_students.columns:\n",
    "        if df_students[col].dtype == bool:\n",
    "            df_students[col] = df_students[col].astype(int)\n",
    "        else:\n",
    "            df_students[col] = (\n",
    "                df_students[col]\n",
    "                .astype(str)\n",
    "                .str.lower()\n",
    "                .replace({\"true\": 1, \"false\": 0, \"yes\": 1, \"no\": 0})\n",
    "                .fillna(0)\n",
    "                .astype(int)\n",
    "            )\n",
    "\n",
    "# Identify other categorical columns & one-hot\n",
    "categorical_cols = [\n",
    "    \"Parental_Involvement\", \"Access_to_Resources\", \"Motivation_Level\",\n",
    "    \"Family_Income\", \"Teacher_Quality\", \"School_Type\", \"Peer_Influence\",\n",
    "    \"Parental_Education_Level\", \"Distance_from_Home\", \"Gender\"\n",
    "]\n",
    "existing_cat = [c for c in categorical_cols if c in df_students.columns]\n",
    "if existing_cat:\n",
    "    df_students = pd.get_dummies(df_students, columns=existing_cat, drop_first=True)\n",
    "\n",
    "# Convert leftover bool\n",
    "bool_cols2 = df_students.select_dtypes(include='bool').columns\n",
    "df_students[bool_cols2] = df_students[bool_cols2].astype(int)\n",
    "\n",
    "target_col = \"Passed\"\n",
    "if target_col not in df_students.columns:\n",
    "    raise KeyError(f\"Target '{target_col}' not found in student dataset.\")\n",
    "\n",
    "# For baseline, we'll remove \"Exam_Score\" from features to avoid direct leak\n",
    "X_stud = df_students.drop(columns=[\"Exam_Score\", target_col])\n",
    "y_stud = df_students[target_col]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_stud_scaled = pd.DataFrame(scaler.fit_transform(X_stud), columns=X_stud.columns)\n",
    "\n",
    "X_train_stud, X_test_stud, y_train_stud, y_test_stud = train_test_split(\n",
    "    X_stud_scaled, y_stud, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "baseline_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "baseline_model.fit(X_train_stud, y_train_stud)\n",
    "\n",
    "y_pred_base = baseline_model.predict(X_test_stud)\n",
    "baseline_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test_stud, y_pred_base),\n",
    "    \"Precision\": precision_score(y_test_stud, y_pred_base, average='weighted', zero_division=0),\n",
    "    \"Recall\": recall_score(y_test_stud, y_pred_base, average='weighted', zero_division=0),\n",
    "    \"F1 Score\": f1_score(y_test_stud, y_pred_base, average='weighted', zero_division=0),\n",
    "}\n",
    "print(\"\\n=== Students Baseline Model ===\")\n",
    "print(baseline_metrics)\n",
    "\n",
    "###############################################################################\n",
    "# 2. SEMI-AUTOMATED FEATURE ENGINEERING\n",
    "###############################################################################\n",
    "print(\"\\nRunning Semi-Automated Feature Engineering (Students)...\")\n",
    "\n",
    "feature_engineer = SemiAutomatedFeatureEngineering(\n",
    "    df_students.copy(),\n",
    "    target_column=target_col,\n",
    "    task=\"classification\"\n",
    ")\n",
    "pipeline_results = feature_engineer.run_pipeline()\n",
    "\n",
    "df_stud_enh = feature_engineer.df\n",
    "X_stud_enh = df_stud_enh.drop(columns=[\"Exam_Score\", target_col], errors='ignore')\n",
    "y_stud_enh = df_stud_enh[target_col]\n",
    "\n",
    "X_stud_enh_scaled = pd.DataFrame(scaler.fit_transform(X_stud_enh), columns=X_stud_enh.columns)\n",
    "\n",
    "X_train_stud2, X_test_stud2, y_train_stud2, y_test_stud2 = train_test_split(\n",
    "    X_stud_enh_scaled, y_stud_enh, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "enh_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "enh_model.fit(X_train_stud2, y_train_stud2)\n",
    "\n",
    "y_pred_enh = enh_model.predict(X_test_stud2)\n",
    "enhanced_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test_stud2, y_pred_enh),\n",
    "    \"Precision\": precision_score(y_test_stud2, y_pred_enh, average='weighted', zero_division=0),\n",
    "    \"Recall\": recall_score(y_test_stud2, y_pred_enh, average='weighted', zero_division=0),\n",
    "    \"F1 Score\": f1_score(y_test_stud2, y_pred_enh, average='weighted', zero_division=0),\n",
    "}\n",
    "print(\"\\n=== Students Enhanced Model ===\")\n",
    "print(enhanced_metrics)\n",
    "\n",
    "# Compare\n",
    "print(\"\\nCompare Baseline vs. Enhanced (Students):\")\n",
    "print(\"Baseline:\", baseline_metrics)\n",
    "print(\"Enhanced:\", enhanced_metrics)\n",
    "\n",
    "base_scores = np.array(list(baseline_metrics.values()))\n",
    "enh_scores = np.array(list(enhanced_metrics.values()))\n",
    "stat, pval = wilcoxon(base_scores, enh_scores)\n",
    "print(f\"\\nWilcoxon: statistic={stat:.4f}, pvalue={pval:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 4: Weather Data (Regression)\n",
    "Goal: Predict maximum temperature (max_temp Â°c) based on weather conditions.\n",
    "\n",
    "- Type: Regression (Target: max_temp Â°c)\n",
    "- Baseline Model: RandomForestRegressor\n",
    "- Enhanced Model: Random Forest with Engineered Features\n",
    "- Comparison Metrics: RÂ², RMSE, MAE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
